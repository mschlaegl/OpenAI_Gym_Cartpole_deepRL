{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5f0392",
   "metadata": {},
   "source": [
    "# OpenAI Gym -- Solved Cartpole using DeepRL\n",
    "\n",
    "Solution for OpenAI Gym's Cartpole environment using deep reeinforcement learning.\n",
    "(C) 2022 Manfred SCHLAEGL <manfred.schlaegl@gmx.at>\n",
    "\n",
    "Code inspired by [(527) Deep Q-Network Training Code - Reinforcement Learning Code Project - YouTube](https://www.youtube.com/watch?v=ewRw996uevM&list=PLZbbT5o_s2xoWNVdDudn51XM8lOuZ_Njv&index=18)\n",
    "but strongly reworked (e.g. Cartpole observations instead of Images; Implemented load, save, play, ...)\n",
    "\n",
    "OpenAI Gym Cartpole Environment: https://www.gymlibrary.ml/environments/classic_control/cart_pole/\n",
    "\n",
    "## Requirements\n",
    " * Standard python packages (numpy, ...)\n",
    " * Matplolib: pip install Matplotlib\n",
    " * OpenAI Gym: pip install gym[all]\n",
    " * Pygame: pip install pygame\n",
    " * PyTorch: pip install torch\n",
    " * PyTorch Torchvision: pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576642df",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bdd77a",
   "metadata": {},
   "source": [
    "### Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1637e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyternotebook/virtualenv/lib/python3.8/site-packages/torchvision/transforms/functional_pil.py:228: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  interpolation: int = Image.BILINEAR,\n",
      "/opt/jupyternotebook/virtualenv/lib/python3.8/site-packages/torchvision/transforms/functional_pil.py:295: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  interpolation: int = Image.NEAREST,\n",
      "/opt/jupyternotebook/virtualenv/lib/python3.8/site-packages/torchvision/transforms/functional_pil.py:328: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  interpolation: int = Image.BICUBIC,\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#from gym import wrappers\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from os.path import exists\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f661a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython: from IPython import display\n",
    "torchdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef2466",
   "metadata": {},
   "source": [
    "### Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac904a0e",
   "metadata": {},
   "source": [
    "#### DQN: Model for policy (and target) network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a29f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN extends nn.Module\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        \"\"\"\n",
    "        model constructor\n",
    "\n",
    "        :param n_inputs: number of inputs\n",
    "        :param n_outputs: number of outputs\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=n_inputs, out_features=24)\n",
    "        self.out = nn.Linear(in_features=24, out_features=n_outputs)\n",
    "\n",
    "    \n",
    "    # overloaded\n",
    "    def forward(self, inputs):\n",
    "        t = inputs.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = self.out(t)\n",
    "        return t\n",
    "\n",
    "    \n",
    "    def clone(self, torchdevice):\n",
    "        \"\"\"\n",
    "        clone this model\n",
    "\n",
    "        :torchdevice:\n",
    "        :return: clone of current model\n",
    "        \"\"\"\n",
    "        clone = DQN(self.n_inputs, self.n_outputs).to(torchdevice)\n",
    "        clone.load_state_dict(self.state_dict())\n",
    "        return clone\n",
    "    \n",
    "    \n",
    "    def save(self, filename):\n",
    "        \"\"\"\n",
    "        save the model to given file\n",
    "\n",
    "        :filename: file to save the model to\n",
    "        \"\"\" \n",
    "        torch.save(self.state_dict(), filename)\n",
    "        \n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\"\n",
    "        load the model from given file\n",
    "\n",
    "        :filename: file to save the model to\n",
    "        :return: False if file does not exist\n",
    "        \"\"\"\n",
    "        if not exists(filename):\n",
    "            return False\n",
    "        \n",
    "        self.load_state_dict(torch.load(filename))\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336375b5",
   "metadata": {},
   "source": [
    "#### Replay Memory for Experience Replay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e20391ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python tuple with named fields\n",
    "Experience = namedtuple(\n",
    "    'Experience',\n",
    "    ('state', 'action', 'next_state', 'reward')\n",
    ")\n",
    "\n",
    "class ReplayMemory():\n",
    "    def __init__(self, capacity):\n",
    "        \"\"\"\n",
    "        initialize with given capacity\n",
    "\n",
    "        :capacity: capacity of the ReplayMemory\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "        self.push_idx = 0\n",
    "       \n",
    "    \n",
    "    def push(self, experience):\n",
    "        \"\"\"\n",
    "        push a new experience\n",
    "        if the memory is full we push in round robin fashion\n",
    "\n",
    "        :experience: Experience to push\n",
    "        \"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_idx] = experience\n",
    "        self.push_idx += 1\n",
    "        if self.push_idx >= self.capacity:\n",
    "            self.push_idx = 0\n",
    "        self.push_count += 1\n",
    "        \n",
    "        \n",
    "    def nElements(self):\n",
    "        \"\"\"\n",
    "        Number of experiences in ReplayMemory\n",
    "\n",
    "        :return: number of experiences in ReplayMemory\n",
    "        \"\"\"\n",
    "        return len(self.memory)\n",
    "        \n",
    "        \n",
    "    def can_provide_sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Enough experiences in ReplayMemory to return batch_size\n",
    "\n",
    "        :batch_size: size of the batch\n",
    "        :return: True if number of experiences > batch_size\n",
    "        \"\"\"\n",
    "        return self.nElements() >= batch_size\n",
    "    \n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        get a random batch of experiences\n",
    "\n",
    "        :batch_size: size of the batch\n",
    "        :return: random batch (None if not enough samples)\n",
    "        \"\"\"\n",
    "        if not self.can_provide_sample(batch_size):\n",
    "            return None\n",
    "        return random.sample(self.memory, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3047cb",
   "metadata": {},
   "source": [
    "#### Agent (and Action Selection Strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec22ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon Greedy Strategy (for Training)\n",
    "class EpsilonGreedyStrategy():\n",
    "    def __init__(self, start, end, decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "        \n",
    "    def get_exploration_rate(self, current_step):\n",
    "        return self.end + (self.start - self.end) * \\\n",
    "            math.exp(-1. * current_step * self.decay)\n",
    "\n",
    "# Exploitation Strategy (for Playing)\n",
    "class ExploitationStrategy():\n",
    "    def get_exploration_rate(self, current_step):\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Agent (Action Selection)\n",
    "class Agent():\n",
    "    def __init__(self, torchdevice, strategy, n_actions):\n",
    "        self.current_step = 0\n",
    "        self.strategy = strategy\n",
    "        self.n_actions = n_actions\n",
    "        self.torchdevice = torchdevice\n",
    "        \n",
    "    def select_action(self, state, policy_net):\n",
    "        \"\"\"\n",
    "        select action w.r.t. given state and configured\n",
    "        strategy\n",
    "\n",
    "        :state: current state\n",
    "        :policy_net: the policy network\n",
    "        :return: action\n",
    "        \"\"\"\n",
    "        rate = self.strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step += 1\n",
    "        \n",
    "        if rate > random.random():\n",
    "            #print('explore')\n",
    "            action = random.randrange(self.n_actions)\n",
    "            return torch.tensor([action]).to(self.torchdevice)\n",
    "        else:\n",
    "            #print('exploit')\n",
    "            with torch.no_grad():\n",
    "                return policy_net(state).argmax(dim=1).to(self.torchdevice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f40e6cd",
   "metadata": {},
   "source": [
    "#### Cartpole Environment Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212485eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleEnvManager():\n",
    "    def __init__(self, torchdevice):\n",
    "        self.torchdevice = torchdevice\n",
    "        # unwrapped gives access to behind the scene elements of env\n",
    "        self.env = gym.make('CartPole-v1').unwrapped\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.state = None\n",
    "        self.done = False\n",
    "        \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "        \n",
    "    def render(self, mode='human'):\n",
    "        return self.env.render(mode)\n",
    "    \n",
    "    def n_observations(self):\n",
    "        return self.env.observation_space.shape[0]\n",
    "    \n",
    "    def n_actions(self):\n",
    "        return self.env.action_space.n\n",
    "    \n",
    "    def take_action(self, action):\n",
    "        \"\"\"\n",
    "        perform action and return reward\n",
    "\n",
    "        :action: action to take\n",
    "        :return: reward\n",
    "        \"\"\"\n",
    "        # action is tensor -> item delivers value of tensor as python number\n",
    "        self.state, reward, self.done, _ = self.env.step(action.item())\n",
    "        return torch.tensor([np.float32(reward)], device=self.torchdevice)\n",
    "\n",
    "    def get_state(self):\n",
    "        if self.state is None or self.done:\n",
    "            # no action was done before\n",
    "            ret=torch.zeros(self.n_observations())\n",
    "        else:\n",
    "            ret=torch.tensor(self.state, device=self.torchdevice)\n",
    "        return ret.unsqueeze(0).to(self.torchdevice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4fad6",
   "metadata": {},
   "source": [
    "#### QValue calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ec8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QValues():\n",
    "    @staticmethod\n",
    "    def get_current(policy_net, states, actions):\n",
    "        return policy_net(states).gather(dim=1, index=actions.unsqueeze(-1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_next(target_net, next_states):\n",
    "        # handling of final states\n",
    "        final_state_locations = next_states.flatten(start_dim=1) \\\n",
    "            .max(dim=1)[0].eq(0).type(torch.bool)\n",
    "        non_final_state_locations = (final_state_locations == False)\n",
    "        non_final_states = next_states[non_final_state_locations]\n",
    "        batch_size = next_states.shape[0]\n",
    "        values = torch.zeros(batch_size).to(torchdevice)\n",
    "        values[non_final_state_locations] = target_net(non_final_states).max(dim=1)[0].detach()\n",
    "        return values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b3088",
   "metadata": {},
   "source": [
    "#### Misc Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d71ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(values, moving_avg_period):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('Performance ...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.plot(values)\n",
    "    \n",
    "    moving_avg = get_moving_average(values, moving_avg_period)\n",
    "    plt.plot(moving_avg)\n",
    "    plt.pause(0.001)\n",
    "    print(\"Episode \" + str(len(values)) + \n",
    "          \" with average reward \" + str(moving_avg[-1]))\n",
    "\n",
    "def plot_results(values, moving_avg_period):\n",
    "    episode_best = np.argmax(values)\n",
    "    moving_avg_best = np.max(values).item()\n",
    "    plot(values, moving_avg_period)\n",
    "        \n",
    "def get_moving_average(values, period):\n",
    "    values = torch.tensor(values, dtype=torch.float)\n",
    "    if len(values) < period:\n",
    "        moving_avg = torch.full((len(values), ), float('-inf'))\n",
    "        return moving_avg.numpy()\n",
    "    \n",
    "    # periode slice and mean\n",
    "    moving_avg = values.unfold(dimension=0, size=period, step=1) \\\n",
    "        .mean(dim=1).flatten(start_dim=0)\n",
    "    moving_avg = torch.cat((torch.zeros(period-1), moving_avg))\n",
    "    return moving_avg.numpy()\n",
    "\n",
    "def extract_tensors(experiences):\n",
    "    batch = Experience(*zip(*experiences))\n",
    "    t1 = torch.cat(batch.state)\n",
    "    t2 = torch.cat(batch.action)\n",
    "    t3 = torch.cat(batch.reward)\n",
    "    t4 = torch.cat(batch.next_state)\n",
    "    return (t1, t2, t3, t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5119c29",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e4b5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters for Training\n",
    "class HyperParameters():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # size of replay memory for experience replay\n",
    "        self.memory_size = 100000\n",
    "        \n",
    "        # batch_size (taken from replay memory)\n",
    "        self.batch_size = 256\n",
    "        \n",
    "        # RL gamma\n",
    "        self.gamma = 0.999\n",
    "        \n",
    "        # exploration rate (start, end, decay)\n",
    "        self.eps_start = 1\n",
    "        self.eps_end = 0.01\n",
    "        self.eps_decay = 0.001\n",
    "        \n",
    "        # episodes after which target_net = policy_net\n",
    "        self.target_update = 10\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = 0.001\n",
    "        \n",
    "        # number of episodes\n",
    "        self.n_episodes = 5000\n",
    "        \n",
    "        # maximum number of timesteps to play\n",
    "        self.max_timestep = 1000 # 500 is success in CartPole-v1\n",
    "        \n",
    "        # number of episodes used to calculate moving reward average\n",
    "        self.n_episodes_ravg = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f3623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(torchdevice, em, filename):\n",
    "    \"\"\"\n",
    "    load a policy network from given file\n",
    "\n",
    "    :torchdevice: torch.device(...)\n",
    "    :em: the environment the model was trained on\n",
    "    :filename: filename\n",
    "    :return: polcy network (None if file not found)\n",
    "    \"\"\"\n",
    "\n",
    "    policy_net = DQN(\n",
    "        em.n_observations(),\n",
    "        em.n_actions()).to(torchdevice)\n",
    "    if not policy_net.load(filename):\n",
    "        return None\n",
    "    return policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "924ed53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(torchdevice, em, hpara, stat_update = 100, policy_net = None):\n",
    "    \"\"\"\n",
    "    train a policy network with given parameters\n",
    "\n",
    "    :torchdevice: torch.device(...)\n",
    "    :em: the environment to train on\n",
    "    :filename: filename\n",
    "    :stat_update: plot statistics after every stat_update episodes (default 100)\n",
    "    :policy_net: optional existing model to train (default None)\n",
    "    :return: (best found policy network, episode rewards)\n",
    "    \"\"\"\n",
    "        \n",
    "    # setup agent\n",
    "    agent = Agent(\n",
    "        torchdevice,\n",
    "        EpsilonGreedyStrategy(\n",
    "            hpara.eps_start,\n",
    "            hpara.eps_end,\n",
    "            hpara.eps_decay),\n",
    "        em.n_actions())\n",
    "    \n",
    "    # setup replay memory (for experience replay)\n",
    "    memory = ReplayMemory(hpara.memory_size)\n",
    "\n",
    "    # create new policy_net (if not given)\n",
    "    if policy_net == None:\n",
    "        policy_net = DQN(\n",
    "            em.n_observations(),\n",
    "            em.n_actions()).to(torchdevice)\n",
    "    policy_net.train() # switch to training mode\n",
    "    \n",
    "    # create target net\n",
    "    target_net = policy_net.clone(torchdevice)\n",
    "    target_net.eval() # only inference\n",
    "    \n",
    "    # setup optimizer\n",
    "    optimizer = optim.Adam(params=policy_net.parameters(), lr=hpara.lr)\n",
    "    \n",
    "    # track best episode\n",
    "    moving_avg_best = float('-inf')\n",
    "    episode_best = 0\n",
    "    policy_net_best = policy_net.clone(torchdevice)\n",
    "    policy_net_best.eval() # only inference    \n",
    "    \n",
    "    # track episode rewards\n",
    "    episode_rewards = []\n",
    "    \n",
    "    # start training\n",
    "    print(\"0: \", end='')\n",
    "    for episode in range(1, hpara.n_episodes + 1):\n",
    "\n",
    "        # start new episode\n",
    "        print(\".\", end='')\n",
    "        em.reset()\n",
    "        \n",
    "        state = em.get_state()\n",
    "        reward_sum = 0\n",
    "        for timestep in count():\n",
    "            \n",
    "            # make a move\n",
    "            action = agent.select_action(state, policy_net)\n",
    "            reward = em.take_action(action)\n",
    "            reward_sum += reward\n",
    "            next_state = em.get_state()\n",
    "            \n",
    "            # \n",
    "            # Use a custom calculated reward for training (Reward Shaping)\n",
    "            # Solves the convergence problem in the training phase (large\n",
    "            # performance jumps while in training)\n",
    "            # Based on https://github.com/keon/deep-q-learning/blob/master/ddqn.py\n",
    "            #\n",
    "            x,x_dot,theta,theta_dot = next_state[0]\n",
    "            r1 = (em.env.x_threshold - abs(x)) / em.env.x_threshold - 0.8\n",
    "            r2 = (em.env.theta_threshold_radians - abs(theta)) / em.env.theta_threshold_radians - 0.5\n",
    "            reward_alt = r1 + r2\n",
    "            reward_alt = torch.tensor([np.float32(reward_alt)], device=torchdevice)\n",
    "            \n",
    "            memory.push(Experience(state, action, next_state, reward_alt))\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            # start training, after we have enough samples in replay memory\n",
    "            if memory.can_provide_sample(hpara.batch_size):\n",
    "                \n",
    "                # get batch of experiences\n",
    "                experiences = memory.sample(hpara.batch_size)\n",
    "                states, actions, rewards, next_states = extract_tensors(experiences)\n",
    "\n",
    "                # calculate qvalues and loss\n",
    "                current_q_values = QValues.get_current(policy_net, states, actions)\n",
    "                next_q_values = QValues.get_next(target_net, next_states)\n",
    "                target_q_values = (next_q_values * hpara.gamma) + rewards\n",
    "                loss = F.mse_loss(current_q_values, target_q_values.unsqueeze(1))\n",
    "                \n",
    "                # pytorch saves grad of w and bias\n",
    "                optimizer.zero_grad()\n",
    "                # computes gradient w.r.t to bias and weights\n",
    "                loss.backward()\n",
    "                # update weight and bias from backward (connection to loss?)\n",
    "                optimizer.step()\n",
    "\n",
    "            \n",
    "            # end of episode?\n",
    "            if em.done or timestep >= hpara.max_timestep:\n",
    "                # statistics\n",
    "                episode_rewards.append(reward_sum)\n",
    "\n",
    "                #\n",
    "                # Save the most recent, best performing model\n",
    "                #\n",
    "                # We observed, that the performance of the agent does not\n",
    "                # converge in some cases. It's performance can fluctuate\n",
    "                # strongly over the training cycle. This means, that there\n",
    "                # is no guarantee, that the model at the end of the training\n",
    "                # is the best performing one.\n",
    "                # Solution: We keep track of the most recent, best performing\n",
    "                # model while in training.\n",
    "                #\n",
    "                # We save the model if these two conditions are met:\n",
    "                # 1. If the model performed well in the last few \n",
    "                #    episodes\n",
    "                #    -> If the moving average of reward is equal or better\n",
    "                #       than what we have seen so far. (equal because we\n",
    "                #       want to save the most recent model)\n",
    "                # 2. To prevent saving a bad performing outlier: If the\n",
    "                #    model performed well in the last episode\n",
    "                #    -> If the last episodes reward is better or equal\n",
    "                #       than the moving average\n",
    "\n",
    "                moving_avg = get_moving_average(\n",
    "                    episode_rewards,\n",
    "                    para.n_episodes_ravg)[-1]\n",
    "                if episode >= para.n_episodes_ravg and \\\n",
    "                    moving_avg >= moving_avg_best and \\\n",
    "                    reward_sum >= moving_avg_best:\n",
    "                    \n",
    "                    moving_avg_best = moving_avg\n",
    "                    episode_best = episode\n",
    "                    policy_net_best.load_state_dict(policy_net.state_dict())\n",
    "                    print(\"\\nsave best: Episode \" + str(episode_best) +\n",
    "                          \" with average reward \" + str(moving_avg_best));\n",
    "\n",
    "                # update target_net\n",
    "                if episode % hpara.target_update == 0:\n",
    "                    target_net.load_state_dict(policy_net.state_dict())\n",
    "    \n",
    "                # output statistics\n",
    "                if episode % stat_update == 0:\n",
    "                    if is_ipython: display.clear_output(wait=True)\n",
    "                    plot(episode_rewards, para.n_episodes_ravg)\n",
    "                    print(\"best: Episode \" + str(episode_best) +\n",
    "                          \" with average reward \" + str(moving_avg_best));\n",
    "                    print(str(episode) + \": \", end='')\n",
    "\n",
    "                break\n",
    "\n",
    "    # return best policy and statistics\n",
    "    \n",
    "    print(\"best: Episode \" + str(episode_best) +\n",
    "          \" with average reward \" + str(moving_avg_best));\n",
    "    policy_net_best.eval() # only inference    \n",
    "    return (policy_net_best, episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7dbc583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(torchdevice, em, policy_net,\n",
    "         n_episodes_ravg = 100,\n",
    "         num_episodes = 1, \n",
    "         max_timestep = 1000):\n",
    "    \"\"\"\n",
    "    play the game using a given policy network\n",
    "\n",
    "    :torchdevice: torch.device(...)\n",
    "    :em: the environment to play on\n",
    "    :policy_net: policy network to use\n",
    "    :num_episodes: number of episodes to play (default 1)\n",
    "    :max_timestep: maximum timesteps to play (default 1000)\n",
    "    :n_episodes_ravg: number of episodes used to calculate moving reward average (for plot) (default 100)\n",
    "    :return: episode rewards\n",
    "    \"\"\"\n",
    "        \n",
    "    # setup agent\n",
    "    agent = Agent(torchdevice,\n",
    "                  ExploitationStrategy(),\n",
    "                  em.n_actions())\n",
    "\n",
    "    # track episode rewards\n",
    "    episode_rewards = []\n",
    "\n",
    "    for episode in range(1, num_episodes + 1):\n",
    "\n",
    "        # start new episode\n",
    "        em.reset()\n",
    "\n",
    "        # play\n",
    "        state = em.get_state()\n",
    "        reward_sum = 0\n",
    "        for timestep in count():\n",
    "\n",
    "            # render output\n",
    "            em.render()\n",
    "\n",
    "            # make a move\n",
    "            action = agent.select_action(state, policy_net)\n",
    "            reward_sum += em.take_action(action)\n",
    "            state = em.get_state()\n",
    "\n",
    "            # end of episode?\n",
    "            if em.done or timestep >= max_timestep:\n",
    "                episode_rewards.append(reward_sum)\n",
    "                if is_ipython: display.clear_output(wait=True)\n",
    "                print(\"Episode \" + str(episode) +\n",
    "                      \" with reward \" + str(reward_sum.item()));\n",
    "\n",
    "                plot(episode_rewards, n_episodes_ravg)\n",
    "                break\n",
    "        \n",
    "    return episode_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307656f",
   "metadata": {},
   "source": [
    "### Main Program\n",
    "If the model file exists and is loadable -> play. If the model file does not exist -> train, save & play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4171b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyternotebook/virtualenv/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# model file to load\n",
    "modelfile=\"OpenAI_Gym_Cartpole_deepRL.model\"\n",
    "\n",
    "# the environment to train/play\n",
    "em = CartPoleEnvManager(torchdevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "587e6869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try loading model\n",
    "policy_net = load(torchdevice, em, modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc98163c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5000 with average reward 1001.0\n",
      "best: Episode 5000 with average reward 1001.0\n",
      "5000: best: Episode 5000 with average reward 1001.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyternotebook/virtualenv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:43: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n",
      "/opt/jupyternotebook/virtualenv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n",
      "/opt/jupyternotebook/virtualenv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/jupyternotebook/virtualenv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5000 with average reward 1001.0\n"
     ]
    }
   ],
   "source": [
    "# if model could not be loaded -> train & save\n",
    "episode_rewards = None\n",
    "para = HyperParameters()\n",
    "if policy_net is None:\n",
    "    policy_net, episode_rewards = train(torchdevice, em, para, 10)\n",
    "    policy_net.save(modelfile)\n",
    "    plot_results(episode_rewards, para.n_episodes_ravg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62159a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5 with reward 1001.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5 with average reward -inf\n"
     ]
    }
   ],
   "source": [
    "# play\n",
    "episode_rewards = play(torchdevice, em, policy_net, para.n_episodes_ravg, 5, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34d8658e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5 with average reward -inf\n"
     ]
    }
   ],
   "source": [
    "# print results of play\n",
    "if episode_rewards is not None:\n",
    "    plot_results(episode_rewards, para.n_episodes_ravg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674f9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
